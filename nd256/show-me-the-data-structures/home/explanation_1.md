The `LRU_Cache` class implements a Least Recently Used (LRU) cache using a combination of a dictionary and a doubly linked list. This design choice is driven by the need to achieve efficient time complexity for both cache accesses and updates. The dictionary provides $O(1)$ time complexity for lookups, which allows us to quickly check if an item is in the cache. The doubly linked list maintains the order of elements based on their usage, enabling $O(1)$ time complexity for both insertion and deletion operations. This is crucial for efficiently updating the cache when items are accessed or evicted.

In terms of space efficiency, the dictionary and doubly linked list together ensure that the cache uses space proportional to the number of items it can hold, i.e., $O(\text{capacity})$. Each item in the cache requires storage for its key and value, as well as pointers for the linked list nodes. While this does introduce some overhead compared to a simple list or array, the trade-off is justified by the significant gains in time efficiency for cache operations.

Overall, the combination of these data structures ensures that the `LRU_Cache` class can handle frequent cache accesses and updates efficiently, making it suitable for applications where quick retrieval and eviction of items are critical.