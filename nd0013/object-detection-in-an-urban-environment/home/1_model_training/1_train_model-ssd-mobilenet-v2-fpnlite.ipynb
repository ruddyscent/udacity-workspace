{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e1cd147",
   "metadata": {},
   "source": [
    "# Tensorflow Object Detection API and AWS Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85592c17",
   "metadata": {},
   "source": [
    "In this notebook, you will train and evaluate different models using the [Tensorflow Object Detection API](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/) and [AWS Sagemaker](https://aws.amazon.com/sagemaker/). \n",
    "\n",
    "If you ever feel stuck, you can refer to this [tutorial](https://aws.amazon.com/blogs/machine-learning/training-and-deploying-models-using-tensorflow-2-with-the-object-detection-api-on-amazon-sagemaker/).\n",
    "\n",
    "## Dataset\n",
    "\n",
    "We are using the [Waymo Open Dataset](https://waymo.com/open/) for this project. The dataset has already been exported using the tfrecords format. The files have been created following the format described [here](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#create-tensorflow-records). You can find data stored on [AWS S3](https://aws.amazon.com/s3/), AWS Object Storage. The images are saved with a resolution of 640x640."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0207bdb4-3385-446c-b0b2-593d19b829aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcc1d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install tensorflow_io sagemaker -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96f55350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "from framework import CustomFramework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccde6fd1",
   "metadata": {},
   "source": [
    "Save the IAM role in a variable called `role`. This would be useful when training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ab6b13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "arn:aws:iam::180228063476:role/service-role/AmazonSageMaker-ExecutionRole-20231023T213640\n"
     ]
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae64e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The train and val paths below are public S3 buckets created by Udacity for this project\n",
    "inputs = {'train': 's3://cd2688-object-detection-tf2/train/', \n",
    "          'val': 's3://cd2688-object-detection-tf2/val/'} \n",
    "\n",
    "# Insert path of a folder in your personal S3 bucket to store tensorboard logs.\n",
    "tensorboard_s3_prefix = 's3://object-detection-project-20231024/logs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc16a825",
   "metadata": {},
   "source": [
    "## Container\n",
    "\n",
    "To train the model, you will first need to build a [docker](https://www.docker.com/) container with all the dependencies required by the TF Object Detection API. The code below does the following:\n",
    "* clone the Tensorflow models repository\n",
    "* get the exporter and training scripts from the the repository\n",
    "* build the docker image and push it \n",
    "* print the container name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ad5ac8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'docker/models' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# clone the repo and get the scripts\n",
    "git clone https://github.com/tensorflow/models.git docker/models\n",
    "\n",
    "# get model_main and exporter_main files from TF2 Object Detection GitHub repository\n",
    "cp docker/models/research/object_detection/exporter_main_v2.py source_dir \n",
    "cp docker/models/research/object_detection/model_main_tf2.py source_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2dab3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and push the docker image. This code can be commented out after being run once.\n",
    "# This will take around 10 mins.\n",
    "# image_name = 'tf2-object-detection'\n",
    "# !sh ./docker/build_and_push.sh $image_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62b3562",
   "metadata": {},
   "source": [
    "To verify that the image was correctly pushed to the [Elastic Container Registry](https://aws.amazon.com/ecr/), you can look at it in the AWS webapp. For example, below you can see that three different images have been pushed to ECR. You should only see one, called `tf2-object-detection`.\n",
    "![ECR Example](../data/example_ecr.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0310b6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180228063476.dkr.ecr.us-east-1.amazonaws.com/tf2-object-detection:20231024170424\n"
     ]
    }
   ],
   "source": [
    "# display the container name\n",
    "with open (os.path.join('docker', 'ecr_image_fullname.txt'), 'r') as f:\n",
    "    container = f.readlines()[0][:-1]\n",
    "\n",
    "print(container)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b2a754",
   "metadata": {},
   "source": [
    "## Pre-trained model from model zoo\n",
    "\n",
    "As often, we are not training from scratch and we will be using a pretrained model from the TF Object Detection model zoo. You can find pretrained checkpoints at the [TensorFlow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md). Because your time is limited for this project, we recommend to only experiment with the following models:\n",
    "* [EfficientDet D1 640x640](http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz)\n",
    "* [SSD MobileNet V2 FPNLite 640x640](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz)\n",
    "* [SSD ResNet50 V1 FPN 640x640 (RetinaNet50)](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz)\n",
    "* [Faster R-CNN ResNet50 V1 640x640](http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz)\n",
    "* [Faster R-CNN ResNet152 V1 640x640](http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet152_v1_640x640_coco17_tpu-8.tar.gz)\n",
    "\n",
    "In the code below, the [EfficientDet D1](http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz) model is downloaded and extracted. This code should be adjusted if you were to experiment with other architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da944139-b82e-4c7c-912f-cadf94dd59d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# rm -rf /tmp/checkpoint source_dir/checkpoint\n",
    "# mkdir /tmp/checkpoint source_dir/checkpoint\n",
    "# wget -O /tmp/efficientdet.tar.gz http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz\n",
    "# tar -zxvf /tmp/efficientdet.tar.gz --strip-components 2 --directory source_dir/checkpoint efficientdet_d1_coco17_tpu-32/checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785f1713-b932-47a6-ac59-85258e84c46c",
   "metadata": {},
   "source": [
    "In the code below, the [SSD MobileNet V2 FPNLite](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz) model is downloaded and extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c68afe4-ad2f-4920-ae30-c3ec193213cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2023-10-24 17:43:55--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 142.251.111.207, 142.251.16.207, 172.253.62.207, ...\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|142.251.111.207|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20518283 (20M) [application/x-tar]\n",
      "Saving to: ‘/tmp/ssd_mobilenet.tar.gz’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0% 9.97M 2s\n",
      "    50K .......... .......... .......... .......... ..........  0% 19.7M 1s\n",
      "   100K .......... .......... .......... .......... ..........  0% 18.4M 1s\n",
      "   150K .......... .......... .......... .......... ..........  0% 21.3M 1s\n",
      "   200K .......... .......... .......... .......... ..........  1% 19.9M 1s\n",
      "   250K .......... .......... .......... .......... ..........  1% 23.1M 1s\n",
      "   300K .......... .......... .......... .......... ..........  1% 14.1M 1s\n",
      "   350K .......... .......... .......... .......... ..........  1% 21.2M 1s\n",
      "   400K .......... .......... .......... .......... ..........  2% 19.2M 1s\n",
      "   450K .......... .......... .......... .......... ..........  2% 21.4M 1s\n",
      "   500K .......... .......... .......... .......... ..........  2% 55.5M 1s\n",
      "   550K .......... .......... .......... .......... ..........  2% 21.1M 1s\n",
      "   600K .......... .......... .......... .......... ..........  3% 21.6M 1s\n",
      "   650K .......... .......... .......... .......... ..........  3% 48.9M 1s\n",
      "   700K .......... .......... .......... .......... ..........  3% 25.6M 1s\n",
      "   750K .......... .......... .......... .......... ..........  3% 24.8M 1s\n",
      "   800K .......... .......... .......... .......... ..........  4% 53.3M 1s\n",
      "   850K .......... .......... .......... .......... ..........  4% 26.0M 1s\n",
      "   900K .......... .......... .......... .......... ..........  4% 27.8M 1s\n",
      "   950K .......... .......... .......... .......... ..........  4% 51.4M 1s\n",
      "  1000K .......... .......... .......... .......... ..........  5% 28.2M 1s\n",
      "  1050K .......... .......... .......... .......... ..........  5% 28.0M 1s\n",
      "  1100K .......... .......... .......... .......... ..........  5% 48.2M 1s\n",
      "  1150K .......... .......... .......... .......... ..........  5% 28.2M 1s\n",
      "  1200K .......... .......... .......... .......... ..........  6% 28.1M 1s\n",
      "  1250K .......... .......... .......... .......... ..........  6% 50.7M 1s\n",
      "  1300K .......... .......... .......... .......... ..........  6% 27.7M 1s\n",
      "  1350K .......... .......... .......... .......... ..........  6% 27.7M 1s\n",
      "  1400K .......... .......... .......... .......... ..........  7% 50.3M 1s\n",
      "  1450K .......... .......... .......... .......... ..........  7% 27.7M 1s\n",
      "  1500K .......... .......... .......... .......... ..........  7% 25.0M 1s\n",
      "  1550K .......... .......... .......... .......... ..........  7% 62.4M 1s\n",
      "  1600K .......... .......... .......... .......... ..........  8% 28.6M 1s\n",
      "  1650K .......... .......... .......... .......... ..........  8% 27.7M 1s\n",
      "  1700K .......... .......... .......... .......... ..........  8% 49.9M 1s\n",
      "  1750K .......... .......... .......... .......... ..........  8% 27.2M 1s\n",
      "  1800K .......... .......... .......... .......... ..........  9% 33.7M 1s\n",
      "  1850K .......... .......... .......... .......... ..........  9% 40.6M 1s\n",
      "  1900K .......... .......... .......... .......... ..........  9% 27.7M 1s\n",
      "  1950K .......... .......... .......... .......... ..........  9% 31.6M 1s\n",
      "  2000K .......... .......... .......... .......... .......... 10% 41.5M 1s\n",
      "  2050K .......... .......... .......... .......... .......... 10% 28.8M 1s\n",
      "  2100K .......... .......... .......... .......... .......... 10% 59.9M 1s\n",
      "  2150K .......... .......... .......... .......... .......... 10% 31.0M 1s\n",
      "  2200K .......... .......... .......... .......... .......... 11% 29.4M 1s\n",
      "  2250K .......... .......... .......... .......... .......... 11% 45.9M 1s\n",
      "  2300K .......... .......... .......... .......... .......... 11% 34.5M 1s\n",
      "  2350K .......... .......... .......... .......... .......... 11% 55.7M 1s\n",
      "  2400K .......... .......... .......... .......... .......... 12% 31.3M 1s\n",
      "  2450K .......... .......... .......... .......... .......... 12% 30.9M 1s\n",
      "  2500K .......... .......... .......... .......... .......... 12% 44.6M 1s\n",
      "  2550K .......... .......... .......... .......... .......... 12% 80.2M 1s\n",
      "  2600K .......... .......... .......... .......... .......... 13% 32.8M 1s\n",
      "  2650K .......... .......... .......... .......... .......... 13% 34.9M 1s\n",
      "  2700K .......... .......... .......... .......... .......... 13% 34.6M 1s\n",
      "  2750K .......... .......... .......... .......... .......... 13% 41.4M 1s\n",
      "  2800K .......... .......... .......... .......... .......... 14% 79.9M 1s\n",
      "  2850K .......... .......... .......... .......... .......... 14% 30.6M 1s\n",
      "  2900K .......... .......... .......... .......... .......... 14% 32.4M 1s\n",
      "  2950K .......... .......... .......... .......... .......... 14% 32.8M 1s\n",
      "  3000K .......... .......... .......... .......... .......... 15% 43.5M 1s\n",
      "  3050K .......... .......... .......... .......... .......... 15% 81.5M 1s\n",
      "  3100K .......... .......... .......... .......... .......... 15% 30.8M 1s\n",
      "  3150K .......... .......... .......... .......... .......... 15% 30.4M 1s\n",
      "  3200K .......... .......... .......... .......... .......... 16% 49.2M 1s\n",
      "  3250K .......... .......... .......... .......... .......... 16% 31.1M 1s\n",
      "  3300K .......... .......... .......... .......... .......... 16% 74.8M 1s\n",
      "  3350K .......... .......... .......... .......... .......... 16% 32.7M 1s\n",
      "  3400K .......... .......... .......... .......... .......... 17% 33.0M 1s\n",
      "  3450K .......... .......... .......... .......... .......... 17% 45.0M 1s\n",
      "  3500K .......... .......... .......... .......... .......... 17% 32.9M 1s\n",
      "  3550K .......... .......... .......... .......... .......... 17% 77.4M 1s\n",
      "  3600K .......... .......... .......... .......... .......... 18% 31.3M 1s\n",
      "  3650K .......... .......... .......... .......... .......... 18% 29.2M 1s\n",
      "  3700K .......... .......... .......... .......... .......... 18% 46.1M 1s\n",
      "  3750K .......... .......... .......... .......... .......... 18% 31.5M 1s\n",
      "  3800K .......... .......... .......... .......... .......... 19% 75.6M 1s\n",
      "  3850K .......... .......... .......... .......... .......... 19% 33.1M 1s\n",
      "  3900K .......... .......... .......... .......... .......... 19% 37.7M 1s\n",
      "  3950K .......... .......... .......... .......... .......... 19% 36.4M 0s\n",
      "  4000K .......... .......... .......... .......... .......... 20% 37.3M 0s\n",
      "  4050K .......... .......... .......... .......... .......... 20% 59.8M 0s\n",
      "  4100K .......... .......... .......... .......... .......... 20% 31.1M 0s\n",
      "  4150K .......... .......... .......... .......... .......... 20% 32.6M 0s\n",
      "  4200K .......... .......... .......... .......... .......... 21% 43.8M 0s\n",
      "  4250K .......... .......... .......... .......... .......... 21% 38.0M 0s\n",
      "  4300K .......... .......... .......... .......... .......... 21% 60.5M 0s\n",
      "  4350K .......... .......... .......... .......... .......... 21% 33.7M 0s\n",
      "  4400K .......... .......... .......... .......... .......... 22% 30.3M 0s\n",
      "  4450K .......... .......... .......... .......... .......... 22% 44.2M 0s\n",
      "  4500K .......... .......... .......... .......... .......... 22% 71.8M 0s\n",
      "  4550K .......... .......... .......... .......... .......... 22% 32.8M 0s\n",
      "  4600K .......... .......... .......... .......... .......... 23% 31.8M 0s\n",
      "  4650K .......... .......... .......... .......... .......... 23% 34.4M 0s\n",
      "  4700K .......... .......... .......... .......... .......... 23% 45.9M 0s\n",
      "  4750K .......... .......... .......... .......... .......... 23% 78.1M 0s\n",
      "  4800K .......... .......... .......... .......... .......... 24% 31.6M 0s\n",
      "  4850K .......... .......... .......... .......... .......... 24% 32.2M 0s\n",
      "  4900K .......... .......... .......... .......... .......... 24% 33.7M 0s\n",
      "  4950K .......... .......... .......... .......... .......... 24% 42.2M 0s\n",
      "  5000K .......... .......... .......... .......... .......... 25% 84.6M 0s\n",
      "  5050K .......... .......... .......... .......... .......... 25% 31.4M 0s\n",
      "  5100K .......... .......... .......... .......... .......... 25% 31.4M 0s\n",
      "  5150K .......... .......... .......... .......... .......... 25% 45.9M 0s\n",
      "  5200K .......... .......... .......... .......... .......... 26% 32.2M 0s\n",
      "  5250K .......... .......... .......... .......... .......... 26% 75.3M 0s\n",
      "  5300K .......... .......... .......... .......... .......... 26% 32.2M 0s\n",
      "  5350K .......... .......... .......... .......... .......... 26% 31.0M 0s\n",
      "  5400K .......... .......... .......... .......... .......... 27% 44.5M 0s\n",
      "  5450K .......... .......... .......... .......... .......... 27% 33.6M 0s\n",
      "  5500K .......... .......... .......... .......... .......... 27% 74.9M 0s\n",
      "  5550K .......... .......... .......... .......... .......... 27% 32.8M 0s\n",
      "  5600K .......... .......... .......... .......... .......... 28% 31.4M 0s\n",
      "  5650K .......... .......... .......... .......... .......... 28% 44.7M 0s\n",
      "  5700K .......... .......... .......... .......... .......... 28% 29.5M 0s\n",
      "  5750K .......... .......... .......... .......... .......... 28% 81.7M 0s\n",
      "  5800K .......... .......... .......... .......... .......... 29% 32.0M 0s\n",
      "  5850K .......... .......... .......... .......... .......... 29% 31.7M 0s\n",
      "  5900K .......... .......... .......... .......... .......... 29% 45.1M 0s\n",
      "  5950K .......... .......... .......... .......... .......... 29% 31.7M 0s\n",
      "  6000K .......... .......... .......... .......... .......... 30% 76.1M 0s\n",
      "  6050K .......... .......... .......... .......... .......... 30% 31.4M 0s\n",
      "  6100K .......... .......... .......... .......... .......... 30% 39.1M 0s\n",
      "  6150K .......... .......... .......... .......... .......... 30% 36.3M 0s\n",
      "  6200K .......... .......... .......... .......... .......... 31% 38.8M 0s\n",
      "  6250K .......... .......... .......... .......... .......... 31% 58.1M 0s\n",
      "  6300K .......... .......... .......... .......... .......... 31% 31.8M 0s\n",
      "  6350K .......... .......... .......... .......... .......... 31% 31.3M 0s\n",
      "  6400K .......... .......... .......... .......... .......... 32% 46.2M 0s\n",
      "  6450K .......... .......... .......... .......... .......... 32% 74.0M 0s\n",
      "  6500K .......... .......... .......... .......... .......... 32% 32.4M 0s\n",
      "  6550K .......... .......... .......... .......... .......... 32% 36.8M 0s\n",
      "  6600K .......... .......... .......... .......... .......... 33% 28.2M 0s\n",
      "  6650K .......... .......... .......... .......... .......... 33% 43.6M 0s\n",
      "  6700K .......... .......... .......... .......... .......... 33% 83.2M 0s\n",
      "  6750K .......... .......... .......... .......... .......... 33% 35.9M 0s\n",
      "  6800K .......... .......... .......... .......... .......... 34% 31.4M 0s\n",
      "  6850K .......... .......... .......... .......... .......... 34% 31.4M 0s\n",
      "  6900K .......... .......... .......... .......... .......... 34% 44.7M 0s\n",
      "  6950K .......... .......... .......... .......... .......... 34% 81.4M 0s\n",
      "  7000K .......... .......... .......... .......... .......... 35% 31.8M 0s\n",
      "  7050K .......... .......... .......... .......... .......... 35% 32.4M 0s\n",
      "  7100K .......... .......... .......... .......... .......... 35% 34.1M 0s\n",
      "  7150K .......... .......... .......... .......... .......... 35% 41.0M 0s\n",
      "  7200K .......... .......... .......... .......... .......... 36% 79.5M 0s\n",
      "  7250K .......... .......... .......... .......... .......... 36% 31.6M 0s\n",
      "  7300K .......... .......... .......... .......... .......... 36% 31.6M 0s\n",
      "  7350K .......... .......... .......... .......... .......... 36% 44.2M 0s\n",
      "  7400K .......... .......... .......... .......... .......... 37% 32.9M 0s\n",
      "  7450K .......... .......... .......... .......... .......... 37%  103M 0s\n",
      "  7500K .......... .......... .......... .......... .......... 37% 37.5M 0s\n",
      "  7550K .......... .......... .......... .......... .......... 37% 37.8M 0s\n",
      "  7600K .......... .......... .......... .......... .......... 38% 46.6M 0s\n",
      "  7650K .......... .......... .......... .......... .......... 38%  166M 0s\n",
      "  7700K .......... .......... .......... .......... .......... 38% 36.4M 0s\n",
      "  7750K .......... .......... .......... .......... .......... 38% 34.9M 0s\n",
      "  7800K .......... .......... .......... .......... .......... 39% 37.7M 0s\n",
      "  7850K .......... .......... .......... .......... .......... 39% 47.1M 0s\n",
      "  7900K .......... .......... .......... .......... .......... 39%  154M 0s\n",
      "  7950K .......... .......... .......... .......... .......... 39% 40.5M 0s\n",
      "  8000K .......... .......... .......... .......... .......... 40% 35.5M 0s\n",
      "  8050K .......... .......... .......... .......... .......... 40% 46.9M 0s\n",
      "  8100K .......... .......... .......... .......... .......... 40% 38.7M 0s\n",
      "  8150K .......... .......... .......... .......... .......... 40%  140M 0s\n",
      "  8200K .......... .......... .......... .......... .......... 41% 38.0M 0s\n",
      "  8250K .......... .......... .......... .......... .......... 41% 37.7M 0s\n",
      "  8300K .......... .......... .......... .......... .......... 41% 39.7M 0s\n",
      "  8350K .......... .......... .......... .......... .......... 41% 47.5M 0s\n",
      "  8400K .......... .......... .......... .......... .......... 42%  146M 0s\n",
      "  8450K .......... .......... .......... .......... .......... 42% 36.7M 0s\n",
      "  8500K .......... .......... .......... .......... .......... 42% 37.1M 0s\n",
      "  8550K .......... .......... .......... .......... .......... 42% 24.4M 0s\n",
      "  8600K .......... .......... .......... .......... .......... 43%  157M 0s\n",
      "  8650K .......... .......... .......... .......... .......... 43%  130M 0s\n",
      "  8700K .......... .......... .......... .......... .......... 43% 39.4M 0s\n",
      "  8750K .......... .......... .......... .......... .......... 43% 36.8M 0s\n",
      "  8800K .......... .......... .......... .......... .......... 44% 39.5M 0s\n",
      "  8850K .......... .......... .......... .......... .......... 44% 60.2M 0s\n",
      "  8900K .......... .......... .......... .......... .......... 44% 87.7M 0s\n",
      "  8950K .......... .......... .......... .......... .......... 44% 37.3M 0s\n",
      "  9000K .......... .......... .......... .......... .......... 45% 49.3M 0s\n",
      "  9050K .......... .......... .......... .......... .......... 45% 43.1M 0s\n",
      "  9100K .......... .......... .......... .......... .......... 45%  364M 0s\n",
      "  9150K .......... .......... .......... .......... .......... 45% 44.8M 0s\n",
      "  9200K .......... .......... .......... .......... .......... 46% 42.8M 0s\n",
      "  9250K .......... .......... .......... .......... .......... 46% 35.5M 0s\n",
      "  9300K .......... .......... .......... .......... .......... 46% 54.5M 0s\n",
      "  9350K .......... .......... .......... .......... .......... 46%  192M 0s\n",
      "  9400K .......... .......... .......... .......... .......... 47% 50.5M 0s\n",
      "  9450K .......... .......... .......... .......... .......... 47% 51.2M 0s\n",
      "  9500K .......... .......... .......... .......... .......... 47% 57.4M 0s\n",
      "  9550K .......... .......... .......... .......... .......... 47%  411M 0s\n",
      "  9600K .......... .......... .......... .......... .......... 48% 51.9M 0s\n",
      "  9650K .......... .......... .......... .......... .......... 48% 53.1M 0s\n",
      "  9700K .......... .......... .......... .......... .......... 48% 49.8M 0s\n",
      "  9750K .......... .......... .......... .......... .......... 48% 52.8M 0s\n",
      "  9800K .......... .......... .......... .......... .......... 49%  213M 0s\n",
      "  9850K .......... .......... .......... .......... .......... 49% 62.7M 0s\n",
      "  9900K .......... .......... .......... .......... .......... 49% 49.8M 0s\n",
      "  9950K .......... .......... .......... .......... .......... 49% 58.2M 0s\n",
      " 10000K .......... .......... .......... .......... .......... 50% 60.9M 0s\n",
      " 10050K .......... .......... .......... .......... .......... 50%  484M 0s\n",
      " 10100K .......... .......... .......... .......... .......... 50% 53.1M 0s\n",
      " 10150K .......... .......... .......... .......... .......... 50% 60.9M 0s\n",
      " 10200K .......... .......... .......... .......... .......... 51% 53.7M 0s\n",
      " 10250K .......... .......... .......... .......... .......... 51% 56.4M 0s\n",
      " 10300K .......... .......... .......... .......... .......... 51%  255M 0s\n",
      " 10350K .......... .......... .......... .......... .......... 51% 63.1M 0s\n",
      " 10400K .......... .......... .......... .......... .......... 52% 59.0M 0s\n",
      " 10450K .......... .......... .......... .......... .......... 52% 54.0M 0s\n",
      " 10500K .......... .......... .......... .......... .......... 52% 56.2M 0s\n",
      " 10550K .......... .......... .......... .......... .......... 52%  536M 0s\n",
      " 10600K .......... .......... .......... .......... .......... 53% 57.3M 0s\n",
      " 10650K .......... .......... .......... .......... .......... 53% 55.3M 0s\n",
      " 10700K .......... .......... .......... .......... .......... 53% 55.4M 0s\n",
      " 10750K .......... .......... .......... .......... .......... 53% 88.5M 0s\n",
      " 10800K .......... .......... .......... .......... .......... 54%  137M 0s\n",
      " 10850K .......... .......... .......... .......... .......... 54% 55.5M 0s\n",
      " 10900K .......... .......... .......... .......... .......... 54% 54.4M 0s\n",
      " 10950K .......... .......... .......... .......... .......... 54% 56.0M 0s\n",
      " 11000K .......... .......... .......... .......... .......... 55% 78.8M 0s\n",
      " 11050K .......... .......... .......... .......... .......... 55%  143M 0s\n",
      " 11100K .......... .......... .......... .......... .......... 55% 53.2M 0s\n",
      " 11150K .......... .......... .......... .......... .......... 55% 65.3M 0s\n",
      " 11200K .......... .......... .......... .......... .......... 56% 59.2M 0s\n",
      " 11250K .......... .......... .......... .......... .......... 56%  499M 0s\n",
      " 11300K .......... .......... .......... .......... .......... 56% 53.0M 0s\n",
      " 11350K .......... .......... .......... .......... .......... 56% 61.8M 0s\n",
      " 11400K .......... .......... .......... .......... .......... 57% 50.2M 0s\n",
      " 11450K .......... .......... .......... .......... .......... 57% 61.1M 0s\n",
      " 11500K .......... .......... .......... .......... .......... 57%  448M 0s\n",
      " 11550K .......... .......... .......... .......... .......... 57% 59.5M 0s\n",
      " 11600K .......... .......... .......... .......... .......... 58% 54.8M 0s\n",
      " 11650K .......... .......... .......... .......... .......... 58% 55.7M 0s\n",
      " 11700K .......... .......... .......... .......... .......... 58% 60.6M 0s\n",
      " 11750K .......... .......... .......... .......... .......... 58%  289M 0s\n",
      " 11800K .......... .......... .......... .......... .......... 59% 62.2M 0s\n",
      " 11850K .......... .......... .......... .......... .......... 59% 54.0M 0s\n",
      " 11900K .......... .......... .......... .......... .......... 59% 57.7M 0s\n",
      " 11950K .......... .......... .......... .......... .......... 59% 56.4M 0s\n",
      " 12000K .......... .......... .......... .......... .......... 60%  492M 0s\n",
      " 12050K .......... .......... .......... .......... .......... 60% 49.6M 0s\n",
      " 12100K .......... .......... .......... .......... .......... 60% 68.4M 0s\n",
      " 12150K .......... .......... .......... .......... .......... 60% 50.1M 0s\n",
      " 12200K .......... .......... .......... .......... .......... 61% 78.1M 0s\n",
      " 12250K .......... .......... .......... .......... .......... 61%  276M 0s\n",
      " 12300K .......... .......... .......... .......... .......... 61% 80.1M 0s\n",
      " 12350K .......... .......... .......... .......... .......... 61% 65.5M 0s\n",
      " 12400K .......... .......... .......... .......... .......... 62% 67.8M 0s\n",
      " 12450K .......... .......... .......... .......... .......... 62% 75.0M 0s\n",
      " 12500K .......... .......... .......... .......... .......... 62%  396M 0s\n",
      " 12550K .......... .......... .......... .......... .......... 62% 55.9M 0s\n",
      " 12600K .......... .......... .......... .......... .......... 63% 78.3M 0s\n",
      " 12650K .......... .......... .......... .......... .......... 63% 97.1M 0s\n",
      " 12700K .......... .......... .......... .......... .......... 63%  104M 0s\n",
      " 12750K .......... .......... .......... .......... .......... 63%  250M 0s\n",
      " 12800K .......... .......... .......... .......... .......... 64% 72.6M 0s\n",
      " 12850K .......... .......... .......... .......... .......... 64% 76.6M 0s\n",
      " 12900K .......... .......... .......... .......... .......... 64% 78.1M 0s\n",
      " 12950K .......... .......... .......... .......... .......... 64%  146M 0s\n",
      " 13000K .......... .......... .......... .......... .......... 65%  148M 0s\n",
      " 13050K .......... .......... .......... .......... .......... 65%  122M 0s\n",
      " 13100K .......... .......... .......... .......... .......... 65% 79.6M 0s\n",
      " 13150K .......... .......... .......... .......... .......... 65% 55.5M 0s\n",
      " 13200K .......... .......... .......... .......... .......... 66%  211M 0s\n",
      " 13250K .......... .......... .......... .......... .......... 66% 87.7M 0s\n",
      " 13300K .......... .......... .......... .......... .......... 66%  116M 0s\n",
      " 13350K .......... .......... .......... .......... .......... 66%  163M 0s\n",
      " 13400K .......... .......... .......... .......... .......... 67%  197M 0s\n",
      " 13450K .......... .......... .......... .......... .......... 67%  341M 0s\n",
      " 13500K .......... .......... .......... .......... .......... 67%  264M 0s\n",
      " 13550K .......... .......... .......... .......... .......... 67%  188M 0s\n",
      " 13600K .......... .......... .......... .......... .......... 68%  115M 0s\n",
      " 13650K .......... .......... .......... .......... .......... 68%  109M 0s\n",
      " 13700K .......... .......... .......... .......... .......... 68%  340M 0s\n",
      " 13750K .......... .......... .......... .......... .......... 68%  112M 0s\n",
      " 13800K .......... .......... .......... .......... .......... 69%  104M 0s\n",
      " 13850K .......... .......... .......... .......... .......... 69%  115M 0s\n",
      " 13900K .......... .......... .......... .......... .......... 69%  106M 0s\n",
      " 13950K .......... .......... .......... .......... .......... 69%  546M 0s\n",
      " 14000K .......... .......... .......... .......... .......... 70% 79.1M 0s\n",
      " 14050K .......... .......... .......... .......... .......... 70%  123M 0s\n",
      " 14100K .......... .......... .......... .......... .......... 70% 93.6M 0s\n",
      " 14150K .......... .......... .......... .......... .......... 70%  129M 0s\n",
      " 14200K .......... .......... .......... .......... .......... 71%  414M 0s\n",
      " 14250K .......... .......... .......... .......... .......... 71%  107M 0s\n",
      " 14300K .......... .......... .......... .......... .......... 71%  107M 0s\n",
      " 14350K .......... .......... .......... .......... .......... 71%  127M 0s\n",
      " 14400K .......... .......... .......... .......... .......... 72%  119M 0s\n",
      " 14450K .......... .......... .......... .......... .......... 72%  304M 0s\n",
      " 14500K .......... .......... .......... .......... .......... 72%  117M 0s\n",
      " 14550K .......... .......... .......... .......... .......... 72%  122M 0s\n",
      " 14600K .......... .......... .......... .......... .......... 73%  125M 0s\n",
      " 14650K .......... .......... .......... .......... .......... 73%  115M 0s\n",
      " 14700K .......... .......... .......... .......... .......... 73%  264M 0s\n",
      " 14750K .......... .......... .......... .......... .......... 73%  121M 0s\n",
      " 14800K .......... .......... .......... .......... .......... 74%  119M 0s\n",
      " 14850K .......... .......... .......... .......... .......... 74% 96.7M 0s\n",
      " 14900K .......... .......... .......... .......... .......... 74%  134M 0s\n",
      " 14950K .......... .......... .......... .......... .......... 74%  278M 0s\n",
      " 15000K .......... .......... .......... .......... .......... 75%  120M 0s\n",
      " 15050K .......... .......... .......... .......... .......... 75%  115M 0s\n",
      " 15100K .......... .......... .......... .......... .......... 75%  133M 0s\n",
      " 15150K .......... .......... .......... .......... .......... 75%  110M 0s\n",
      " 15200K .......... .......... .......... .......... .......... 76%  350M 0s\n",
      " 15250K .......... .......... .......... .......... .......... 76% 98.2M 0s\n",
      " 15300K .......... .......... .......... .......... .......... 76%  104M 0s\n",
      " 15350K .......... .......... .......... .......... .......... 76%  163M 0s\n",
      " 15400K .......... .......... .......... .......... .......... 77%  233M 0s\n",
      " 15450K .......... .......... .......... .......... .......... 77%  147M 0s\n",
      " 15500K .......... .......... .......... .......... .......... 77%  120M 0s\n",
      " 15550K .......... .......... .......... .......... .......... 77%  118M 0s\n",
      " 15600K .......... .......... .......... .......... .......... 78%  110M 0s\n",
      " 15650K .......... .......... .......... .......... .......... 78%  444M 0s\n",
      " 15700K .......... .......... .......... .......... .......... 78%  118M 0s\n",
      " 15750K .......... .......... .......... .......... .......... 78%  143M 0s\n",
      " 15800K .......... .......... .......... .......... .......... 79%  119M 0s\n",
      " 15850K .......... .......... .......... .......... .......... 79%  135M 0s\n",
      " 15900K .......... .......... .......... .......... .......... 79%  336M 0s\n",
      " 15950K .......... .......... .......... .......... .......... 79%  116M 0s\n",
      " 16000K .......... .......... .......... .......... .......... 80%  116M 0s\n",
      " 16050K .......... .......... .......... .......... .......... 80%  161M 0s\n",
      " 16100K .......... .......... .......... .......... .......... 80%  121M 0s\n",
      " 16150K .......... .......... .......... .......... .......... 80%  382M 0s\n",
      " 16200K .......... .......... .......... .......... .......... 81%  116M 0s\n",
      " 16250K .......... .......... .......... .......... .......... 81%  106M 0s\n",
      " 16300K .......... .......... .......... .......... .......... 81%  163M 0s\n",
      " 16350K .......... .......... .......... .......... .......... 81%  154M 0s\n",
      " 16400K .......... .......... .......... .......... .......... 82%  236M 0s\n",
      " 16450K .......... .......... .......... .......... .......... 82%  120M 0s\n",
      " 16500K .......... .......... .......... .......... .......... 82%  129M 0s\n",
      " 16550K .......... .......... .......... .......... .......... 82%  126M 0s\n",
      " 16600K .......... .......... .......... .......... .......... 83%  145M 0s\n",
      " 16650K .......... .......... .......... .......... .......... 83%  359M 0s\n",
      " 16700K .......... .......... .......... .......... .......... 83%  131M 0s\n",
      " 16750K .......... .......... .......... .......... .......... 83%  111M 0s\n",
      " 16800K .......... .......... .......... .......... .......... 84%  157M 0s\n",
      " 16850K .......... .......... .......... .......... .......... 84%  152M 0s\n",
      " 16900K .......... .......... .......... .......... .......... 84%  208M 0s\n",
      " 16950K .......... .......... .......... .......... .......... 84%  118M 0s\n",
      " 17000K .......... .......... .......... .......... .......... 85%  155M 0s\n",
      " 17050K .......... .......... .......... .......... .......... 85%  131M 0s\n",
      " 17100K .......... .......... .......... .......... .......... 85%  159M 0s\n",
      " 17150K .......... .......... .......... .......... .......... 85%  225M 0s\n",
      " 17200K .......... .......... .......... .......... .......... 86%  125M 0s\n",
      " 17250K .......... .......... .......... .......... .......... 86%  128M 0s\n",
      " 17300K .......... .......... .......... .......... .......... 86%  172M 0s\n",
      " 17350K .......... .......... .......... .......... .......... 86%  279M 0s\n",
      " 17400K .......... .......... .......... .......... .......... 87%  144M 0s\n",
      " 17450K .......... .......... .......... .......... .......... 87%  130M 0s\n",
      " 17500K .......... .......... .......... .......... .......... 87%  122M 0s\n",
      " 17550K .......... .......... .......... .......... .......... 87%  162M 0s\n",
      " 17600K .......... .......... .......... .......... .......... 88%  270M 0s\n",
      " 17650K .......... .......... .......... .......... .......... 88%  141M 0s\n",
      " 17700K .......... .......... .......... .......... .......... 88%  139M 0s\n",
      " 17750K .......... .......... .......... .......... .......... 88%  120M 0s\n",
      " 17800K .......... .......... .......... .......... .......... 89%  146M 0s\n",
      " 17850K .......... .......... .......... .......... .......... 89%  306M 0s\n",
      " 17900K .......... .......... .......... .......... .......... 89%  133M 0s\n",
      " 17950K .......... .......... .......... .......... .......... 89%  121M 0s\n",
      " 18000K .......... .......... .......... .......... .......... 90%  164M 0s\n",
      " 18050K .......... .......... .......... .......... .......... 90%  128M 0s\n",
      " 18100K .......... .......... .......... .......... .......... 90%  301M 0s\n",
      " 18150K .......... .......... .......... .......... .......... 90%  120M 0s\n",
      " 18200K .......... .......... .......... .......... .......... 91%  162M 0s\n",
      " 18250K .......... .......... .......... .......... .......... 91%  120M 0s\n",
      " 18300K .......... .......... .......... .......... .......... 91%  137M 0s\n",
      " 18350K .......... .......... .......... .......... .......... 91%  218M 0s\n",
      " 18400K .......... .......... .......... .......... .......... 92%  268M 0s\n",
      " 18450K .......... .......... .......... .......... .......... 92%  134M 0s\n",
      " 18500K .......... .......... .......... .......... .......... 92%  146M 0s\n",
      " 18550K .......... .......... .......... .......... .......... 92%  139M 0s\n",
      " 18600K .......... .......... .......... .......... .......... 93%  344M 0s\n",
      " 18650K .......... .......... .......... .......... .......... 93%  130M 0s\n",
      " 18700K .......... .......... .......... .......... .......... 93%  136M 0s\n",
      " 18750K .......... .......... .......... .......... .......... 93%  123M 0s\n",
      " 18800K .......... .......... .......... .......... .......... 94%  180M 0s\n",
      " 18850K .......... .......... .......... .......... .......... 94%  194M 0s\n",
      " 18900K .......... .......... .......... .......... .......... 94%  180M 0s\n",
      " 18950K .......... .......... .......... .......... .......... 94%  115M 0s\n",
      " 19000K .......... .......... .......... .......... .......... 95%  167M 0s\n",
      " 19050K .......... .......... .......... .......... .......... 95%  168M 0s\n",
      " 19100K .......... .......... .......... .......... .......... 95%  240M 0s\n",
      " 19150K .......... .......... .......... .......... .......... 95%  132M 0s\n",
      " 19200K .......... .......... .......... .......... .......... 96%  137M 0s\n",
      " 19250K .......... .......... .......... .......... .......... 96%  141M 0s\n",
      " 19300K .......... .......... .......... .......... .......... 96%  440M 0s\n",
      " 19350K .......... .......... .......... .......... .......... 96%  129M 0s\n",
      " 19400K .......... .......... .......... .......... .......... 97%  142M 0s\n",
      " 19450K .......... .......... .......... .......... .......... 97%  120M 0s\n",
      " 19500K .......... .......... .......... .......... .......... 97%  126M 0s\n",
      " 19550K .......... .......... .......... .......... .......... 97%  481M 0s\n",
      " 19600K .......... .......... .......... .......... .......... 98%  200M 0s\n",
      " 19650K .......... .......... .......... .......... .......... 98%  120M 0s\n",
      " 19700K .......... .......... .......... .......... .......... 98%  181M 0s\n",
      " 19750K .......... .......... .......... .......... .......... 98%  138M 0s\n",
      " 19800K .......... .......... .......... .......... .......... 99%  368M 0s\n",
      " 19850K .......... .......... .......... .......... .......... 99%  149M 0s\n",
      " 19900K .......... .......... .......... .......... .......... 99%  133M 0s\n",
      " 19950K .......... .......... .......... .......... .......... 99%  137M 0s\n",
      " 20000K .......... .......... .......... .......              100%  660M=0.3s\n",
      "\n",
      "2023-10-24 17:43:55 (56.5 MB/s) - ‘/tmp/ssd_mobilenet.tar.gz’ saved [20518283/20518283]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -rf /tmp/checkpoint source_dir/checkpoint\n",
    "mkdir /tmp/checkpoint source_dir/checkpoint\n",
    "wget -O /tmp/ssd_mobilenet.tar.gz http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
    "tar -zxvf /tmp/ssd_mobilenet.tar.gz --strip-components 2 --directory source_dir/checkpoint ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c66938-8f86-44fa-aa34-d9f0d954b18a",
   "metadata": {},
   "source": [
    "In the code below, the [SSD ResNet50 V1 FPN (RetinaNet50)](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz) model is downloaded and extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df931597-8dcd-4eb4-a293-9f64110f43f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# rm -rf /tmp/checkpoint source_dir/checkpoint\n",
    "# mkdir /tmp/checkpoint source_dir/checkpoint\n",
    "# wget -O /tmp/ssd_resnet50.tar.gz http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
    "# tar -zxvf /tmp/ssd_resnet50.tar.gz --strip-components 2 --directory source_dir/checkpoint ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0dc46c-8af5-4bbb-b269-f6d09196d3c2",
   "metadata": {},
   "source": [
    "In the code below, the [Faster R-CNN ResNet50 V1](http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz) model is downloaded and extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b309690d-fe9b-432c-bf21-28222759f02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# rm -rf /tmp/checkpoint source_dir/checkpoint\n",
    "# mkdir /tmp/checkpoint source_dir/checkpoint\n",
    "# wget -O /tmp/faster_rcnn_resnet50.tar.gz http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n",
    "# tar -zxvf /tmp/faster_rcnn_resnet50.tar.gz --strip-components 2 --directory source_dir/checkpoint faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38d3486-037a-44af-8848-6ee51e72e0eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "In the code below, the [Faster R-CNN ResNet152 V1](http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet152_v1_640x640_coco17_tpu-8.tar.gz) model is downloaded and extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "982f18f1-e454-42b2-9219-9e34bdb80562",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# rm -rf /tmp/checkpoint source_dir/checkpoint\n",
    "# mkdir /tmp/checkpoint source_dir/checkpoint\n",
    "# wget -O /tmp/faster_rcnn_resnet152.tar.gz http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet152_v1_640x640_coco17_tpu-8.tar.gz\n",
    "# tar -zxvf /tmp/faster_rcnn_resnet152.tar.gz --strip-components 2 --directory source_dir/checkpoint faster_rcnn_resnet152_v1_640x640_coco17_tpu-8/checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e04a98",
   "metadata": {},
   "source": [
    "## Edit pipeline.config file\n",
    "\n",
    "The [`pipeline.config`](source_dir/pipeline.config) in the `source_dir` folder should be updated when you experiment with different models. The different config files are available [here](https://github.com/tensorflow/models/tree/master/research/object_detection/configs/tf2).\n",
    "\n",
    ">Note: The provided `pipeline.config` file works well with the `EfficientDet` model. You would need to modify it when working with other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47483545",
   "metadata": {},
   "source": [
    "## Launch Training Job\n",
    "\n",
    "Now that we have a dataset, a docker image and some pretrained model weights, we can launch the training job. To do so, we create a [Sagemaker Framework](https://sagemaker.readthedocs.io/en/stable/frameworks/index.html), where we indicate the container name, name of the config file, number of training steps etc.\n",
    "\n",
    "The `run_training.sh` script does the following:\n",
    "* train the model for `num_train_steps` \n",
    "* evaluate over the val dataset\n",
    "* export the model\n",
    "\n",
    "Different metrics will be displayed during the evaluation phase, including the mean average precision. These metrics can be used to quantify your model performances and compare over the different iterations.\n",
    "\n",
    "You can also monitor the training progress by navigating to **Training -> Training Jobs** from the Amazon Sagemaker dashboard in the Web UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c7175cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: tf2-object-detection-2023-10-24-17-43-56-548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-24 17:43:57 Starting - Starting the training job...\n",
      "2023-10-24 17:44:13 Starting - Preparing the instances for training......\n",
      "2023-10-24 17:45:20 Downloading - Downloading input data...\n",
      "2023-10-24 17:45:45 Training - Downloading the training image...............\n",
      "2023-10-24 17:48:26 Training - Training image download completed. Training in progress....\u001b[34m2023-10-24 17:48:44,804 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-24 17:48:44,830 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-24 17:48:44,857 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-24 17:48:44,869 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"val\": \"/opt/ml/input/data/val\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"/opt/training\",\n",
      "        \"num_train_steps\": \"2000\",\n",
      "        \"pipeline_config_path\": \"ssd-mobilenet-v2-fpnlite.config\",\n",
      "        \"sample_1_of_n_eval_examples\": \"1\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"val\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"tf2-object-detection-2023-10-24-17-43-56-548\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-180228063476/tf2-object-detection-2023-10-24-17-43-56-548/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_training.sh\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_training.sh\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"/opt/training\",\"num_train_steps\":\"2000\",\"pipeline_config_path\":\"ssd-mobilenet-v2-fpnlite.config\",\"sample_1_of_n_eval_examples\":\"1\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_training.sh\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"val\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_training.sh\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-180228063476/tf2-object-detection-2023-10-24-17-43-56-548/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"val\":\"/opt/ml/input/data/val\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"model_dir\":\"/opt/training\",\"num_train_steps\":\"2000\",\"pipeline_config_path\":\"ssd-mobilenet-v2-fpnlite.config\",\"sample_1_of_n_eval_examples\":\"1\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"tf2-object-detection-2023-10-24-17-43-56-548\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-180228063476/tf2-object-detection-2023-10-24-17-43-56-548/source/sourcedir.tar.gz\",\"module_name\":\"run_training.sh\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_training.sh\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"/opt/training\",\"--num_train_steps\",\"2000\",\"--pipeline_config_path\",\"ssd-mobilenet-v2-fpnlite.config\",\"--sample_1_of_n_eval_examples\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VAL=/opt/ml/input/data/val\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=/opt/training\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_STEPS=2000\u001b[0m\n",
      "\u001b[34mSM_HP_PIPELINE_CONFIG_PATH=ssd-mobilenet-v2-fpnlite.config\u001b[0m\n",
      "\u001b[34mSM_HP_SAMPLE_1_OF_N_EVAL_EXAMPLES=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python38.zip:/usr/lib/python3.8:/usr/lib/python3.8/lib-dynload:/usr/local/lib/python3.8/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/bin/sh -c \"./run_training.sh --model_dir /opt/training --num_train_steps 2000 --pipeline_config_path ssd-mobilenet-v2-fpnlite.config --sample_1_of_n_eval_examples 1\"\u001b[0m\n",
      "\u001b[34m2023-10-24 17:48:44,869 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m===TRAINING THE MODEL==\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\u001b[0m\n",
      "\u001b[34mI1024 17:48:50.120908 139678640371520 mirrored_strategy.py:419] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting train_steps: 2000\u001b[0m\n",
      "\u001b[34mI1024 17:48:50.314878 139678640371520 config_util.py:552] Maybe overwriting train_steps: 2000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mI1024 17:48:50.315016 139678640371520 config_util.py:552] Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mrename to distribute_datasets_from_function\u001b[0m\n",
      "\u001b[34mW1024 17:48:50.337413 139678640371520 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mrename to distribute_datasets_from_function\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading unweighted datasets: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI1024 17:48:50.343131 139678640371520 dataset_builder.py:162] Reading unweighted datasets: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading record datasets for input file: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI1024 17:48:50.344154 139678640371520 dataset_builder.py:79] Reading record datasets for input file: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Number of filenames to read: 84\u001b[0m\n",
      "\u001b[34mI1024 17:48:50.344238 139678640371520 dataset_builder.py:80] Number of filenames to read: 84\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mW1024 17:48:50.350098 139678640371520 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mW1024 17:48:50.365164 139678640371520 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mW1024 17:48:56.607892 139678640371520 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34m`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\u001b[0m\n",
      "\u001b[34mW1024 17:48:59.459674 139678640371520 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34m`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW1024 17:49:00.845102 139678640371520 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mI1024 17:49:09.443997 139649911613184 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI1024 17:49:17.120101 139649911613184 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1024 17:49:23.030164 139678640371520 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1024 17:49:23.032312 139678640371520 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1024 17:49:23.033078 139678640371520 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1024 17:49:23.033744 139678640371520 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1024 17:49:23.036325 139678640371520 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1024 17:49:23.036978 139678640371520 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1024 17:49:23.037697 139678640371520 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1024 17:49:23.038334 139678640371520 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1024 17:49:23.041557 139678640371520 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1024 17:49:23.042249 139678640371520 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse fn_output_signature instead\u001b[0m\n",
      "\u001b[34mW1024 17:49:24.005942 139673089328896 deprecation.py:569] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse fn_output_signature instead\u001b[0m\n",
      "\u001b[34mI1024 17:49:24.978438 139673089328896 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI1024 17:49:29.671709 139673089328896 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI1024 17:49:34.181138 139673089328896 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI1024 17:49:38.696202 139673089328896 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 100 per-step time 0.517s\u001b[0m\n",
      "\u001b[34mI1024 17:50:15.437303 139678640371520 model_lib_v2.py:705] Step 100 per-step time 0.517s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.30972424,\n",
      " 'Loss/localization_loss': 0.4696835,\n",
      " 'Loss/regularization_loss': 0.15143012,\n",
      " 'Loss/total_loss': 0.93083787,\n",
      " 'learning_rate': 0.0319994}\u001b[0m\n",
      "\u001b[34mI1024 17:50:15.437640 139678640371520 model_lib_v2.py:708] {'Loss/classification_loss': 0.30972424,\n",
      " 'Loss/localization_loss': 0.4696835,\n",
      " 'Loss/regularization_loss': 0.15143012,\n",
      " 'Loss/total_loss': 0.93083787,\n",
      " 'learning_rate': 0.0319994}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 200 per-step time 0.225s\u001b[0m\n",
      "\u001b[34mI1024 17:50:37.789061 139678640371520 model_lib_v2.py:705] Step 200 per-step time 0.225s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.3115788,\n",
      " 'Loss/localization_loss': 0.43951705,\n",
      " 'Loss/regularization_loss': 0.15143482,\n",
      " 'Loss/total_loss': 0.9025307,\n",
      " 'learning_rate': 0.0373328}\u001b[0m\n",
      "\u001b[34mI1024 17:50:37.789323 139678640371520 model_lib_v2.py:708] {'Loss/classification_loss': 0.3115788,\n",
      " 'Loss/localization_loss': 0.43951705,\n",
      " 'Loss/regularization_loss': 0.15143482,\n",
      " 'Loss/total_loss': 0.9025307,\n",
      " 'learning_rate': 0.0373328}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 300 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mI1024 17:51:00.142408 139678640371520 model_lib_v2.py:705] Step 300 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.24431868,\n",
      " 'Loss/localization_loss': 0.3344088,\n",
      " 'Loss/regularization_loss': 0.15140054,\n",
      " 'Loss/total_loss': 0.73012805,\n",
      " 'learning_rate': 0.0426662}\u001b[0m\n",
      "\u001b[34mI1024 17:51:00.142672 139678640371520 model_lib_v2.py:708] {'Loss/classification_loss': 0.24431868,\n",
      " 'Loss/localization_loss': 0.3344088,\n",
      " 'Loss/regularization_loss': 0.15140054,\n",
      " 'Loss/total_loss': 0.73012805,\n",
      " 'learning_rate': 0.0426662}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 400 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mI1024 17:51:22.514174 139678640371520 model_lib_v2.py:705] Step 400 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.2772388,\n",
      " 'Loss/localization_loss': 0.41419092,\n",
      " 'Loss/regularization_loss': 0.15135646,\n",
      " 'Loss/total_loss': 0.8427862,\n",
      " 'learning_rate': 0.047999598}\u001b[0m\n",
      "\u001b[34mI1024 17:51:22.514428 139678640371520 model_lib_v2.py:708] {'Loss/classification_loss': 0.2772388,\n",
      " 'Loss/localization_loss': 0.41419092,\n",
      " 'Loss/regularization_loss': 0.15135646,\n",
      " 'Loss/total_loss': 0.8427862,\n",
      " 'learning_rate': 0.047999598}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 500 per-step time 0.223s\u001b[0m\n",
      "\u001b[34mI1024 17:51:44.862648 139678640371520 model_lib_v2.py:705] Step 500 per-step time 0.223s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.25280038,\n",
      " 'Loss/localization_loss': 0.3478715,\n",
      " 'Loss/regularization_loss': 0.15129958,\n",
      " 'Loss/total_loss': 0.7519715,\n",
      " 'learning_rate': 0.053333}\u001b[0m\n",
      "\u001b[34mI1024 17:51:44.862888 139678640371520 model_lib_v2.py:708] {'Loss/classification_loss': 0.25280038,\n",
      " 'Loss/localization_loss': 0.3478715,\n",
      " 'Loss/regularization_loss': 0.15129958,\n",
      " 'Loss/total_loss': 0.7519715,\n",
      " 'learning_rate': 0.053333}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 600 per-step time 0.223s\u001b[0m\n",
      "\u001b[34mI1024 17:52:07.204304 139678640371520 model_lib_v2.py:705] Step 600 per-step time 0.223s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.29171276,\n",
      " 'Loss/localization_loss': 0.29588133,\n",
      " 'Loss/regularization_loss': 0.15122707,\n",
      " 'Loss/total_loss': 0.73882115,\n",
      " 'learning_rate': 0.0586664}\u001b[0m\n",
      "\u001b[34mI1024 17:52:07.204546 139678640371520 model_lib_v2.py:708] {'Loss/classification_loss': 0.29171276,\n",
      " 'Loss/localization_loss': 0.29588133,\n",
      " 'Loss/regularization_loss': 0.15122707,\n",
      " 'Loss/total_loss': 0.73882115,\n",
      " 'learning_rate': 0.0586664}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 700 per-step time 0.223s\u001b[0m\n",
      "\u001b[34mI1024 17:52:29.548483 139678640371520 model_lib_v2.py:705] Step 700 per-step time 0.223s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.20897906,\n",
      " 'Loss/localization_loss': 0.29328623,\n",
      " 'Loss/regularization_loss': 0.15106277,\n",
      " 'Loss/total_loss': 0.65332806,\n",
      " 'learning_rate': 0.0639998}\u001b[0m\n",
      "\u001b[34mI1024 17:52:29.548724 139678640371520 model_lib_v2.py:708] {'Loss/classification_loss': 0.20897906,\n",
      " 'Loss/localization_loss': 0.29328623,\n",
      " 'Loss/regularization_loss': 0.15106277,\n",
      " 'Loss/total_loss': 0.65332806,\n",
      " 'learning_rate': 0.0639998}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 800 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mI1024 17:52:51.913098 139678640371520 model_lib_v2.py:705] Step 800 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.2563496,\n",
      " 'Loss/localization_loss': 0.31494227,\n",
      " 'Loss/regularization_loss': 0.15097214,\n",
      " 'Loss/total_loss': 0.722264,\n",
      " 'learning_rate': 0.069333196}\u001b[0m\n",
      "\u001b[34mI1024 17:52:51.913337 139678640371520 model_lib_v2.py:708] {'Loss/classification_loss': 0.2563496,\n",
      " 'Loss/localization_loss': 0.31494227,\n",
      " 'Loss/regularization_loss': 0.15097214,\n",
      " 'Loss/total_loss': 0.722264,\n",
      " 'learning_rate': 0.069333196}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 900 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mI1024 17:53:14.263513 139678640371520 model_lib_v2.py:705] Step 900 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.18745367,\n",
      " 'Loss/localization_loss': 0.27604014,\n",
      " 'Loss/regularization_loss': 0.1509485,\n",
      " 'Loss/total_loss': 0.61444235,\n",
      " 'learning_rate': 0.074666604}\u001b[0m\n",
      "\u001b[34mI1024 17:53:14.263760 139678640371520 model_lib_v2.py:708] {'Loss/classification_loss': 0.18745367,\n",
      " 'Loss/localization_loss': 0.27604014,\n",
      " 'Loss/regularization_loss': 0.1509485,\n",
      " 'Loss/total_loss': 0.61444235,\n",
      " 'learning_rate': 0.074666604}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1000 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mI1024 17:53:36.615559 139678640371520 model_lib_v2.py:705] Step 1000 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.19865647,\n",
      " 'Loss/localization_loss': 0.2734023,\n",
      " 'Loss/regularization_loss': 0.15083379,\n",
      " 'Loss/total_loss': 0.62289256,\n",
      " 'learning_rate': 0.08}\u001b[0m\n",
      "\u001b[34mI1024 17:53:36.615804 139678640371520 model_lib_v2.py:708] {'Loss/classification_loss': 0.19865647,\n",
      " 'Loss/localization_loss': 0.2734023,\n",
      " 'Loss/regularization_loss': 0.15083379,\n",
      " 'Loss/total_loss': 0.62289256,\n",
      " 'learning_rate': 0.08}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1100 per-step time 0.232s\u001b[0m\n",
      "\u001b[34mI1024 17:53:59.793590 139678640371520 model_lib_v2.py:705] Step 1100 per-step time 0.232s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.18804844,\n",
      " 'Loss/localization_loss': 0.23134084,\n",
      " 'Loss/regularization_loss': 0.15068166,\n",
      " 'Loss/total_loss': 0.5700709,\n",
      " 'learning_rate': 0.07999918}\u001b[0m\n",
      "\u001b[34mI1024 17:53:59.793853 139678640371520 model_lib_v2.py:708] {'Loss/classification_loss': 0.18804844,\n",
      " 'Loss/localization_loss': 0.23134084,\n",
      " 'Loss/regularization_loss': 0.15068166,\n",
      " 'Loss/total_loss': 0.5700709,\n",
      " 'learning_rate': 0.07999918}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1200 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mI1024 17:54:22.147257 139678640371520 model_lib_v2.py:705] Step 1200 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.26127586,\n",
      " 'Loss/localization_loss': 0.26353955,\n",
      " 'Loss/regularization_loss': 0.15057343,\n",
      " 'Loss/total_loss': 0.6753889,\n",
      " 'learning_rate': 0.079996705}\u001b[0m\n",
      "\u001b[34mI1024 17:54:22.147497 139678640371520 model_lib_v2.py:708] {'Loss/classification_loss': 0.26127586,\n",
      " 'Loss/localization_loss': 0.26353955,\n",
      " 'Loss/regularization_loss': 0.15057343,\n",
      " 'Loss/total_loss': 0.6753889,\n",
      " 'learning_rate': 0.079996705}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1300 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mI1024 17:54:44.520474 139678640371520 model_lib_v2.py:705] Step 1300 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.21090905,\n",
      " 'Loss/localization_loss': 0.30676904,\n",
      " 'Loss/regularization_loss': 0.15044984,\n",
      " 'Loss/total_loss': 0.6681279,\n",
      " 'learning_rate': 0.0799926}\u001b[0m\n",
      "\u001b[34mI1024 17:54:44.520714 139678640371520 model_lib_v2.py:708] {'Loss/classification_loss': 0.21090905,\n",
      " 'Loss/localization_loss': 0.30676904,\n",
      " 'Loss/regularization_loss': 0.15044984,\n",
      " 'Loss/total_loss': 0.6681279,\n",
      " 'learning_rate': 0.0799926}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1400 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mI1024 17:55:06.873551 139678640371520 model_lib_v2.py:705] Step 1400 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.25904977,\n",
      " 'Loss/localization_loss': 0.33379453,\n",
      " 'Loss/regularization_loss': 0.15016675,\n",
      " 'Loss/total_loss': 0.74301106,\n",
      " 'learning_rate': 0.07998685}\u001b[0m\n",
      "\u001b[34mI1024 17:55:06.873815 139678640371520 model_lib_v2.py:708] {'Loss/classification_loss': 0.25904977,\n",
      " 'Loss/localization_loss': 0.33379453,\n",
      " 'Loss/regularization_loss': 0.15016675,\n",
      " 'Loss/total_loss': 0.74301106,\n",
      " 'learning_rate': 0.07998685}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1500 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mI1024 17:55:29.231809 139678640371520 model_lib_v2.py:705] Step 1500 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.20480111,\n",
      " 'Loss/localization_loss': 0.23414278,\n",
      " 'Loss/regularization_loss': 0.1499218,\n",
      " 'Loss/total_loss': 0.5888657,\n",
      " 'learning_rate': 0.07997945}\u001b[0m\n",
      "\u001b[34mI1024 17:55:29.232055 139678640371520 model_lib_v2.py:708] {'Loss/classification_loss': 0.20480111,\n",
      " 'Loss/localization_loss': 0.23414278,\n",
      " 'Loss/regularization_loss': 0.1499218,\n",
      " 'Loss/total_loss': 0.5888657,\n",
      " 'learning_rate': 0.07997945}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1600 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mI1024 17:55:51.585846 139678640371520 model_lib_v2.py:705] Step 1600 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.22632903,\n",
      " 'Loss/localization_loss': 0.30263928,\n",
      " 'Loss/regularization_loss': 0.14982706,\n",
      " 'Loss/total_loss': 0.6787954,\n",
      " 'learning_rate': 0.079970405}\u001b[0m\n",
      "\u001b[34mI1024 17:55:51.586078 139678640371520 model_lib_v2.py:708] {'Loss/classification_loss': 0.22632903,\n",
      " 'Loss/localization_loss': 0.30263928,\n",
      " 'Loss/regularization_loss': 0.14982706,\n",
      " 'Loss/total_loss': 0.6787954,\n",
      " 'learning_rate': 0.079970405}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1700 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mI1024 17:56:13.950648 139678640371520 model_lib_v2.py:705] Step 1700 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.2042762,\n",
      " 'Loss/localization_loss': 0.2604843,\n",
      " 'Loss/regularization_loss': 0.14961806,\n",
      " 'Loss/total_loss': 0.6143786,\n",
      " 'learning_rate': 0.07995972}\u001b[0m\n",
      "\u001b[34mI1024 17:56:13.950883 139678640371520 model_lib_v2.py:708] {'Loss/classification_loss': 0.2042762,\n",
      " 'Loss/localization_loss': 0.2604843,\n",
      " 'Loss/regularization_loss': 0.14961806,\n",
      " 'Loss/total_loss': 0.6143786,\n",
      " 'learning_rate': 0.07995972}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1800 per-step time 0.223s\u001b[0m\n",
      "\u001b[34mI1024 17:56:36.299315 139678640371520 model_lib_v2.py:705] Step 1800 per-step time 0.223s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.16452853,\n",
      " 'Loss/localization_loss': 0.19011906,\n",
      " 'Loss/regularization_loss': 0.14931479,\n",
      " 'Loss/total_loss': 0.5039624,\n",
      " 'learning_rate': 0.0799474}\u001b[0m\n",
      "\u001b[34mI1024 17:56:36.299547 139678640371520 model_lib_v2.py:708] {'Loss/classification_loss': 0.16452853,\n",
      " 'Loss/localization_loss': 0.19011906,\n",
      " 'Loss/regularization_loss': 0.14931479,\n",
      " 'Loss/total_loss': 0.5039624,\n",
      " 'learning_rate': 0.0799474}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1900 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mI1024 17:56:58.679021 139678640371520 model_lib_v2.py:705] Step 1900 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.20661925,\n",
      " 'Loss/localization_loss': 0.324183,\n",
      " 'Loss/regularization_loss': 0.14914814,\n",
      " 'Loss/total_loss': 0.67995036,\n",
      " 'learning_rate': 0.07993342}\u001b[0m\n",
      "\u001b[34mI1024 17:56:58.679259 139678640371520 model_lib_v2.py:708] {'Loss/classification_loss': 0.20661925,\n",
      " 'Loss/localization_loss': 0.324183,\n",
      " 'Loss/regularization_loss': 0.14914814,\n",
      " 'Loss/total_loss': 0.67995036,\n",
      " 'learning_rate': 0.07993342}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 2000 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mI1024 17:57:21.030725 139678640371520 model_lib_v2.py:705] Step 2000 per-step time 0.224s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.16230112,\n",
      " 'Loss/localization_loss': 0.19864109,\n",
      " 'Loss/regularization_loss': 0.14879994,\n",
      " 'Loss/total_loss': 0.50974214,\n",
      " 'learning_rate': 0.07991781}\u001b[0m\n",
      "\u001b[34mI1024 17:57:21.030961 139678640371520 model_lib_v2.py:708] {'Loss/classification_loss': 0.16230112,\n",
      " 'Loss/localization_loss': 0.19864109,\n",
      " 'Loss/regularization_loss': 0.14879994,\n",
      " 'Loss/total_loss': 0.50974214,\n",
      " 'learning_rate': 0.07991781}\u001b[0m\n",
      "\u001b[34m==EVALUATING THE MODEL==\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\u001b[0m\n",
      "\u001b[34mW1024 17:57:26.788368 140544063653696 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\u001b[0m\n",
      "\u001b[34mI1024 17:57:26.788536 140544063653696 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mI1024 17:57:26.788630 140544063653696 config_util.py:552] Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting eval_num_epochs: 1\u001b[0m\n",
      "\u001b[34mI1024 17:57:26.788709 140544063653696 config_util.py:552] Maybe overwriting eval_num_epochs: 1\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\u001b[0m\n",
      "\u001b[34mW1024 17:57:26.788814 140544063653696 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading unweighted datasets: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI1024 17:57:27.054746 140544063653696 dataset_builder.py:162] Reading unweighted datasets: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading record datasets for input file: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI1024 17:57:27.055658 140544063653696 dataset_builder.py:79] Reading record datasets for input file: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Number of filenames to read: 13\u001b[0m\n",
      "\u001b[34mI1024 17:57:27.055754 140544063653696 dataset_builder.py:80] Number of filenames to read: 13\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:num_readers has been reduced to 13 to match input file shards.\u001b[0m\n",
      "\u001b[34mW1024 17:57:27.055822 140544063653696 dataset_builder.py:86] num_readers has been reduced to 13 to match input file shards.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:`shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.\u001b[0m\n",
      "\u001b[34mW1024 17:57:27.057579 140544063653696 dataset_builder.py:93] `shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mW1024 17:57:27.058892 140544063653696 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mW1024 17:57:27.073935 140544063653696 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mW1024 17:57:30.727347 140544063653696 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW1024 17:57:31.759866 140544063653696 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mI1024 17:57:34.061944 140544063653696 checkpoint_utils.py:168] Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Found new checkpoint at /opt/training/ckpt-3\u001b[0m\n",
      "\u001b[34mI1024 17:57:34.062540 140544063653696 checkpoint_utils.py:177] Found new checkpoint at /opt/training/ckpt-3\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mI1024 17:57:38.845481 140544063653696 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI1024 17:57:50.509767 140544063653696 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW1024 17:57:54.582524 140544063653696 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 0\u001b[0m\n",
      "\u001b[34mI1024 17:57:54.675136 140544063653696 model_lib_v2.py:966] Finished eval step 0\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:460: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mtf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \u001b[0m\n",
      "\u001b[34mW1024 17:57:54.805846 140544063653696 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:460: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mtf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"model_main_tf2.py\", line 114, in <module>\n",
      "    tf.compat.v1.app.run()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 308, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 254, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"model_main_tf2.py\", line 81, in main\n",
      "    model_lib_v2.eval_continuously(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py\", line 1158, in eval_continuously\n",
      "    eager_eval_loop(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py\", line 970, in eager_eval_loop\n",
      "    sbys_image_list = vutils.draw_side_by_side_evaluation_image(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/object_detection/utils/visualization_utils.py\", line 713, in draw_side_by_side_evaluation_image\n",
      "    images_with_detections = draw_bounding_boxes_on_image_tensors(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/object_detection/utils/visualization_utils.py\", line 622, in draw_bounding_boxes_on_image_tensors\n",
      "    images = tf.map_fn(draw_boxes, elems, dtype=tf.uint8, back_prop=False)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py\", line 576, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/map_fn.py\", line 498, in map_fn\n",
      "    _, r_a = while_loop.while_loop(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/while_loop.py\", line 499, in while_loop\n",
      "    loop_vars = body(*loop_vars)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/while_loop.py\", line 490, in <lambda>\n",
      "    body = lambda i, lv: (i + 1, orig_body(*lv))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/map_fn.py\", line 488, in compute\n",
      "    result_value = autographed_fn(elems_value)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\", line 693, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\", line 690, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\", line 439, in converted_call\n",
      "    result = converted_f(*effective_args, **kwargs)\n",
      "  File \"/tmp/__autograph_generated_filesw5gh163.py\", line 47, in tf__draw_boxes\n",
      "    image_with_boxes = ag__.converted_call(ag__.ld(tf).py_func, (ag__.ld(visualize_boxes_fn), ag__.ld(image_and_detections)[2:], ag__.ld(tf).uint8), None, fscope)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\", line 377, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\", line 460, in _call_unconverted\n",
      "    return f(*args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py\", line 371, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/object_detection/utils/visualization_utils.py\", line 398, in visualization_py_func_fn\n",
      "    return visualize_boxes_and_labels_on_image_array(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/object_detection/utils/visualization_utils.py\", line 1251, in visualize_boxes_and_labels_on_image_array\n",
      "    draw_bounding_box_on_image_array(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/object_detection/utils/visualization_utils.py\", line 160, in draw_bounding_box_on_image_array\n",
      "    draw_bounding_box_on_image(image_pil, ymin, xmin, ymax, xmax, color,\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/object_detection/utils/visualization_utils.py\", line 219, in draw_bounding_box_on_image\n",
      "    display_str_heights = [font.getbbox(ds)[3] for ds in display_str_list]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/object_detection/utils/visualization_utils.py\", line 219, in <listcomp>\n",
      "    display_str_heights = [font.getbbox(ds)[3] for ds in display_str_list]\u001b[0m\n",
      "\u001b[34mAttributeError: in user code:\n",
      "    File \"/usr/local/lib/python3.8/dist-packages/object_detection/utils/visualization_utils.py\", line 618, in draw_boxes  *\n",
      "        image_with_boxes = tf.py_func(visualize_boxes_fn, image_and_detections[2:],\n",
      "    File \"/usr/local/lib/python3.8/dist-packages/object_detection/utils/visualization_utils.py\", line 398, in visualization_py_func_fn\n",
      "        return visualize_boxes_and_labels_on_image_array(\n",
      "    File \"/usr/local/lib/python3.8/dist-packages/object_detection/utils/visualization_utils.py\", line 1251, in visualize_boxes_and_labels_on_image_array\n",
      "        draw_bounding_box_on_image_array(\n",
      "    File \"/usr/local/lib/python3.8/dist-packages/object_detection/utils/visualization_utils.py\", line 160, in draw_bounding_box_on_image_array\n",
      "        draw_bounding_box_on_image(image_pil, ymin, xmin, ymax, xmax, color,\n",
      "    File \"/usr/local/lib/python3.8/dist-packages/object_detection/utils/visualization_utils.py\", line 219, in draw_bounding_box_on_image\n",
      "        display_str_heights = [font.getbbox(ds)[3] for ds in display_str_list]\n",
      "    File \"/usr/local/lib/python3.8/dist-packages/object_detection/utils/visualization_utils.py\", line 219, in <listcomp>\n",
      "        display_str_heights = [font.getbbox(ds)[3] for ds in display_str_list]\n",
      "    AttributeError: 'ImageFont' object has no attribute 'getbbox'\u001b[0m\n",
      "\u001b[34m==EXPORTING THE MODEL==\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mback_prop=False is deprecated. Consider using tf.stop_gradient instead.\u001b[0m\n",
      "\u001b[34mInstead of:\u001b[0m\n",
      "\u001b[34mresults = tf.map_fn(fn, elems, back_prop=False)\u001b[0m\n",
      "\u001b[34mUse:\u001b[0m\n",
      "\u001b[34mresults = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\u001b[0m\n",
      "\u001b[34mW1024 17:57:58.996254 140113979922240 deprecation.py:641] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mback_prop=False is deprecated. Consider using tf.stop_gradient instead.\u001b[0m\n",
      "\u001b[34mInstead of:\u001b[0m\n",
      "\u001b[34mresults = tf.map_fn(fn, elems, back_prop=False)\u001b[0m\n",
      "\u001b[34mUse:\u001b[0m\n",
      "\u001b[34mresults = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\u001b[0m\n",
      "\u001b[34mI1024 17:58:02.675396 140113979922240 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI1024 17:58:11.391769 140113979922240 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI1024 17:58:14.165573 140113979922240 signature_serialization.py:148] Function `call_func` contains input name(s) resource with unsupported characters which will be renamed to weightsharedconvolutionalboxpredictor_predictiontower_conv2d_3_batchnorm_feature_4_fusedbatchnormv3_readvariableop_1_resource in the SavedModel.\u001b[0m\n",
      "\u001b[34mI1024 17:58:15.204257 140113979922240 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f6e20037490>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.504949 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f6e20037490>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f6d94c11f40>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.913307 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f6d94c11f40>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6da411dca0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.913481 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6da411dca0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94a2bcd0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.913603 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94a2bcd0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f6d94a2b8b0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.913688 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f6d94a2b8b0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d94a2bb20>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.913789 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d94a2bb20>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94a2be80>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.913894 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94a2be80>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f6d94c450d0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.913979 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f6d94c450d0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d94c45b50>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.914064 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d94c45b50>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94c45e80>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.914141 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94c45e80>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f6d94adb5e0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.914219 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7f6d94adb5e0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d94c467f0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.914324 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d94c467f0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94c46460>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.914408 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94c46460>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6dcc11e4c0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.914514 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6dcc11e4c0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d947ec3a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.914608 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d947ec3a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d947ec550>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.914695 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d947ec550>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d947ec790>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.914806 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d947ec790>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d947ecee0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.914887 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d947ecee0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d947ecf10>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.914990 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d947ecf10>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d94b37400>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.915085 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d94b37400>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94b374f0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.915162 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94b374f0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6da41f0820>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.915311 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6da41f0820>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94ac4190>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.915388 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94ac4190>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d94ac5c40>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.915470 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d94ac5c40>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6da4154910>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.915549 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6da4154910>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6da404acd0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.915648 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6da404acd0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6da404aac0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.915750 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6da404aac0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6da404a910>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.915834 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6da404a910>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d949a4af0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.915914 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d949a4af0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d949a4b20>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.915992 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d949a4b20>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94adf310>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.916060 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94adf310>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d94b646a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.916130 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d94b646a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94b64520>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.916235 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94b64520>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d94b64880>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.916310 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d94b64880>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94b64af0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.916390 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94b64af0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d94ae9190>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.916472 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d94ae9190>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94ae9130>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.916540 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94ae9130>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d949ab730>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.916613 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d949ab730>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94a56b50>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.916707 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94a56b50>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d94adc970>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.916799 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d94adc970>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94adc370>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.916887 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94adc370>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d94adcdf0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.916960 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d94adcdf0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94adcbe0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.917042 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94adcbe0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d94d5c040>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.917134 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f6d94d5c040>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94d5cc70>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1024 17:58:17.917233 140113979922240 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7f6d94d5cc70>, because it is not built.\u001b[0m\n",
      "\u001b[34mI1024 17:58:27.104745 140113979922240 save.py:274] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 173). These functions will not be directly callable after loading.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /tmp/exported/saved_model/assets\u001b[0m\n",
      "\u001b[34mI1024 17:58:32.293820 140113979922240 builder_impl.py:804] Assets written to: /tmp/exported/saved_model/assets\u001b[0m\n",
      "\u001b[34mI1024 17:58:32.656214 140113979922240 fingerprinting_utils.py:48] Writing fingerprint to /tmp/exported/saved_model/fingerprint.pb\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Writing pipeline config file to /tmp/exported/pipeline.config\u001b[0m\n",
      "\u001b[34mI1024 17:58:33.094253 140113979922240 config_util.py:253] Writing pipeline config file to /tmp/exported/pipeline.config\u001b[0m\n",
      "\u001b[34m2023-10-24 17:58:34,222 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-10-24 17:58:42 Uploading - Uploading generated training model\n",
      "2023-10-24 17:58:53 Completed - Training job completed\n",
      "Training seconds: 813\n",
      "Billable seconds: 813\n"
     ]
    }
   ],
   "source": [
    "tensorboard_output_config = sagemaker.debugger.TensorBoardOutputConfig(\n",
    "    s3_output_path=tensorboard_s3_prefix,\n",
    "    container_local_output_path='/opt/training/'\n",
    ")\n",
    "\n",
    "estimator = CustomFramework(\n",
    "    role=role,\n",
    "    image_uri=container,\n",
    "    entry_point='run_training.sh',\n",
    "    source_dir='source_dir/',\n",
    "    hyperparameters={\n",
    "        \"model_dir\":\"/opt/training\",        \n",
    "        \"pipeline_config_path\": \"ssd-mobilenet-v2-fpnlite.config\",\n",
    "        \"num_train_steps\": \"2000\",    \n",
    "        \"sample_1_of_n_eval_examples\": \"1\"\n",
    "    },\n",
    "    instance_count=1,\n",
    "    instance_type='ml.g5.xlarge',\n",
    "    tensorboard_output_config=tensorboard_output_config,\n",
    "    disable_profiler=True,\n",
    "    base_job_name='tf2-object-detection'\n",
    ")\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84545881",
   "metadata": {},
   "source": [
    "You should be able to see your model training in the AWS webapp as shown below:\n",
    "![ECR Example](../data/example_trainings.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9844f25",
   "metadata": {},
   "source": [
    "## Improve on the initial model\n",
    "\n",
    "Most likely, this initial experiment did not yield optimal results. However, you can make multiple changes to the `pipeline.config` file to improve this model. One obvious change consists in improving the data augmentation strategy. The [`preprocessor.proto`](https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto) file contains the different data augmentation method available in the Tf Object Detection API. Justify your choices of augmentations in the write-up.\n",
    "\n",
    "Keep in mind that the following are also available:\n",
    "* experiment with the optimizer: type of optimizer, learning rate, scheduler etc\n",
    "* experiment with the architecture. The Tf Object Detection API model zoo offers many architectures. Keep in mind that the pipeline.config file is unique for each architecture and you will have to edit it.\n",
    "* visualize results on the test frames using the `2_deploy_model` notebook available in this repository.\n",
    "\n",
    "In the cell below, write down all the different approaches you have experimented with, why you have chosen them and what you would have done if you had more time and resources. Justify your choices using the tensorboard visualizations (take screenshots and insert them in your write-up), the metrics on the evaluation set and the generated animation you have created with [this tool](../2_run_inference/2_deploy_model.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f6e352-1a4f-438a-a252-bb579a289989",
   "metadata": {
    "tags": []
   },
   "source": [
    "The training was successful for the following three models. On a mAP basis, the EfficientDet D1 model performed the best.\n",
    "* [EfficientDet D1 640x640](http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz)\n",
    "* [SSD MobileNet V2 FPNLite 640x640](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz)\n",
    "* [SSD ResNet50 V1 FPN 640x640 (RetinaNet50)](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606d3f40-8fd8-439c-886a-6e46e9d76c86",
   "metadata": {},
   "source": [
    "### EfficientDet D1 640x640\n",
    "I made the following changes to the pipeline.config included in the model's pretrianed weight.\n",
    "```diff\n",
    "--- efficientdet_d1_coco17_tpu-32/pipeline.config\t2020-07-11 09:12:41\n",
    "+++ efficientdet.config\t2023-06-26 22:37:44\n",
    "@@ -1,6 +1,6 @@\n",
    " model {\n",
    "   ssd {\n",
    "-    num_classes: 90\n",
    "+    num_classes: 3\n",
    "     image_resizer {\n",
    "       keep_aspect_ratio_resizer {\n",
    "         min_dimension: 640\n",
    "@@ -131,7 +131,7 @@\n",
    "   }\n",
    " }\n",
    " train_config {\n",
    "-  batch_size: 128\n",
    "+  batch_size: 8\n",
    "   data_augmentation_options {\n",
    "     random_horizontal_flip {\n",
    "     }\n",
    "@@ -158,20 +158,20 @@\n",
    "     }\n",
    "     use_moving_average: false\n",
    "   }\n",
    "-  fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
    "+  fine_tune_checkpoint: \"checkpoint/ckpt-0\"\n",
    "   num_steps: 300000\n",
    "   startup_delay_steps: 0.0\n",
    "   replicas_to_aggregate: 8\n",
    "   max_number_of_boxes: 100\n",
    "   unpad_groundtruth_tensors: false\n",
    "-  fine_tune_checkpoint_type: \"classification\"\n",
    "+  fine_tune_checkpoint_type: \"detection\"\n",
    "   use_bfloat16: true\n",
    "   fine_tune_checkpoint_version: V2\n",
    " }\n",
    " train_input_reader: {\n",
    "-  label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\n",
    "+  label_map_path: \"/opt/ml/input/data/train/label_map.pbtxt\"\n",
    "   tf_record_input_reader {\n",
    "-    input_path: \"PATH_TO_BE_CONFIGURED/train2017-?????-of-00256.tfrecord\"\n",
    "+    input_path: \"/opt/ml/input/data/train/*.tfrecord\"\n",
    "   }\n",
    " }\n",
    "\n",
    "@@ -182,10 +182,11 @@\n",
    " }\n",
    "\n",
    " eval_input_reader: {\n",
    "-  label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\n",
    "+  label_map_path: \"/opt/ml/input/data/val/label_map.pbtxt\"\n",
    "   shuffle: false\n",
    "   num_epochs: 1\n",
    "   tf_record_input_reader {\n",
    "-    input_path: \"PATH_TO_BE_CONFIGURED/val2017-?????-of-00032.tfrecord\"\n",
    "+    input_path: \"/opt/ml/input/data/val/*.tfrecord\"\n",
    "   }\n",
    " }\n",
    "+\n",
    "```\n",
    "\n",
    "The learning rate increases from 0.00416 at step 100 to 0.0642 at step 2,000.\n",
    "\n",
    "![efficientdet-lr](images/efficientdet-lr.png)\n",
    "\n",
    "The mAP for the evaluation set is 0.08881.\n",
    "\n",
    "![efficientdet-map](images/efficientdet-map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4346b883-898b-44f3-8025-be89c30167d2",
   "metadata": {},
   "source": [
    "### SSD MobileNet V2 FPNLite 640x640\n",
    "I made the following changes to the pipeline.config included in the model's pretrianed weight.\n",
    "```diff\n",
    "--- ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/pipeline.config\t2020-07-11 09:16:23\n",
    "+++ ssd_mobilenet_v2_fpnlite.config\t2023-06-26 23:03:30\n",
    "@@ -1,6 +1,6 @@\n",
    " model {\n",
    "   ssd {\n",
    "-    num_classes: 90\n",
    "+    num_classes: 8\n",
    "     image_resizer {\n",
    "       fixed_shape_resizer {\n",
    "         height: 640\n",
    "@@ -132,7 +132,7 @@\n",
    "   }\n",
    " }\n",
    " train_config {\n",
    "-  batch_size: 128\n",
    "+  batch_size: 8\n",
    "   data_augmentation_options {\n",
    "     random_horizontal_flip {\n",
    "     }\n",
    "@@ -162,19 +162,19 @@\n",
    "     }\n",
    "     use_moving_average: false\n",
    "   }\n",
    "-  fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
    "+  fine_tune_checkpoint: \"checkpoint/ckpt-0\"\n",
    "   num_steps: 50000\n",
    "   startup_delay_steps: 0.0\n",
    "   replicas_to_aggregate: 8\n",
    "   max_number_of_boxes: 100\n",
    "   unpad_groundtruth_tensors: false\n",
    "-  fine_tune_checkpoint_type: \"classification\"\n",
    "+  fine_tune_checkpoint_type: \"detection\"\n",
    "   fine_tune_checkpoint_version: V2\n",
    " }\n",
    " train_input_reader {\n",
    "-  label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
    "+  label_map_path: \"/opt/ml/input/data/train/label_map.pbtxt\"\n",
    "   tf_record_input_reader {\n",
    "-    input_path: \"PATH_TO_BE_CONFIGURED\"\n",
    "+    input_path: \"/opt/ml/input/data/train/*.tfrecord\"\n",
    "   }\n",
    " }\n",
    " eval_config {\n",
    "@@ -182,10 +182,11 @@\n",
    "   use_moving_averages: false\n",
    " }\n",
    " eval_input_reader {\n",
    "-  label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
    "+  label_map_path: \"/opt/ml/input/data/val/label_map.pbtxt\"\n",
    "   shuffle: false\n",
    "   num_epochs: 1\n",
    "   tf_record_input_reader {\n",
    "-    input_path: \"PATH_TO_BE_CONFIGURED\"\n",
    "+    input_path: \"/opt/ml/input/data/val/*.tfrecord\"\n",
    "   }\n",
    " }\n",
    "+\n",
    "```\n",
    "\n",
    "The learning rate increases from 0.032 at step 100 to 0.07989 at step 2,000.\n",
    "\n",
    "![ssd-mobilenet-v2-fpnlite-lr](images/ssd-mobilenet-v2-fpnlite-lr.png)\n",
    "\n",
    "The mAP for the evaluation set is 0.06231.\n",
    "\n",
    "![ssd-mobilenet-v2-fpnlite-map](images/ssd-mobilenet-v2-fpnlite-map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f045d2f-7d09-4cb4-b861-4a24b7c06faa",
   "metadata": {},
   "source": [
    "### SSD ResNet50 V1 FPN 640x640 (RetinaNet50)\n",
    "I made the following changes to the pipeline.config included in the model's pretrianed weight.\n",
    "```diff\n",
    "--- ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/pipeline.config\t2020-07-11 09:16:36\n",
    "+++ ssd-resnet50-v1-fpn.config\t2023-06-26 23:13:19\n",
    "@@ -1,6 +1,6 @@\n",
    " model {\n",
    "   ssd {\n",
    "-    num_classes: 90\n",
    "+    num_classes: 3\n",
    "     image_resizer {\n",
    "       fixed_shape_resizer {\n",
    "         height: 640\n",
    "@@ -128,7 +128,7 @@\n",
    "   }\n",
    " }\n",
    " train_config {\n",
    "-  batch_size: 64\n",
    "+  batch_size: 8\n",
    "   data_augmentation_options {\n",
    "     random_horizontal_flip {\n",
    "     }\n",
    "@@ -158,20 +158,20 @@\n",
    "     }\n",
    "     use_moving_average: false\n",
    "   }\n",
    "-  fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
    "+  fine_tune_checkpoint: \"checkpoint/ckpt-0\"\n",
    "   num_steps: 25000\n",
    "   startup_delay_steps: 0.0\n",
    "   replicas_to_aggregate: 8\n",
    "   max_number_of_boxes: 100\n",
    "   unpad_groundtruth_tensors: false\n",
    "-  fine_tune_checkpoint_type: \"classification\"\n",
    "+  fine_tune_checkpoint_type: \"detection\"\n",
    "   use_bfloat16: true\n",
    "   fine_tune_checkpoint_version: V2\n",
    " }\n",
    "-train_input_reader {\n",
    "-  label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
    "+train_input_reader: {\n",
    "+  label_map_path: \"/opt/ml/input/data/train/label_map.pbtxt\"\n",
    "   tf_record_input_reader {\n",
    "-    input_path: \"PATH_TO_BE_CONFIGURED\"\n",
    "+    input_path: \"/opt/ml/input/data/train/*.tfrecord\"\n",
    "   }\n",
    " }\n",
    " eval_config {\n",
    "@@ -179,10 +179,11 @@\n",
    "   use_moving_averages: false\n",
    " }\n",
    " eval_input_reader {\n",
    "-  label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
    "+  label_map_path: \"/opt/ml/input/data/val/label_map.pbtxt\"\n",
    "   shuffle: false\n",
    "   num_epochs: 1\n",
    "   tf_record_input_reader {\n",
    "-    input_path: \"PATH_TO_BE_CONFIGURED\"\n",
    "+    input_path: \"/opt/ml/input/data/val/*.tfrecord\"\n",
    "   }\n",
    " }\n",
    "+\n",
    "```\n",
    "\n",
    "The learning rate increases from 0.01467 at step 100 to 0.4 at step 2,000.\n",
    "\n",
    "![ssd-resnet50-v1-fpn-lr](images/ssd-resnet50-v1-fpn-lr.png)\n",
    "\n",
    "The mAP for the evaluation set is 0.04913.\n",
    "\n",
    "![ssd-resnet50-v1-fpn-map](images/ssd-resnet50-v1-fpn-map.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5216463d-a7d4-40f7-a124-41cc10566659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
